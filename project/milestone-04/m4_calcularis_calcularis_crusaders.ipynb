{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef",
   "metadata": {
    "id": "8af48ca1-b6d1-4092-b7b5-037d3c2d7aef"
   },
   "source": [
    "# M4 | Research Investigation Notebook\n",
    "\n",
    "In this notebook, you will do a research investigation of your chosen dataset in teams. You will begin by formally selecting your research question (task 0), then processing your data (task 1), creating a predictive model (task 2), evaluating your model's results (task 3), and describing the contributions of each team member (task 4).\n",
    "\n",
    "For grading, please make sure your notebook has all cells run and is stored in your team's [Github Classroom repository](https://classroom.github.com/a/CNxME27U). You will also need to write a short, 2 page report about your design decisions as a team, to be stored in your repository. The Milestone 4 submission will be the contents of your repository at the due date (April 28 at 23:59 CET).\n",
    "\n",
    "## Brief overview of Calcularis\n",
    "[Calcularis](https://school.alemira.com/de/calcularis/) by Alemira School is a mathematics learning program developed with neuroscientists and computer scientists from ETH Zurich. It promotes the development and interaction of the different areas of the brain that are responsible for processing numbers and quantities and solving mathematical tasks. Calcularis can be used from 1st grade to high school. Children with dyscalculia also benefit in the long term and overcome their arithmetic weakness.\n",
    "\n",
    "The Calcularis dataset has three main tables:\n",
    "* ***users***: meta information about users (i.e. total time spent learning with Calcularis, geographic location).\n",
    "* ***events***: events done by the users in the platform (i.e. playing a game, selecting a new animal in the zoo simulation).\n",
    "* ***subtasks***: sub-tasks with answer attempts solved by users, primarily in the context of game events.\n",
    "\n",
    "These tables and useful metadata information are described in detail in the [Milestone 2 data exploration notebook](https://github.com/epfl-ml4ed/mlbd-2023/blob/main/project/milestone-02/m2_calcularis_sciper.ipynb).\n",
    "\n",
    "We have provided access to the [full dataset](https://moodle.epfl.ch/mod/forum/discuss.php?d=88179) (~65k users) and a randomly selected subset (~1k users from M2). We have also provided access to a [test account to experiment with Calcularis](https://moodle.epfl.ch/mod/forum/discuss.php?d=88094). You should provide arguments and justifications for all of your design decisions throughout this investigation. You can use your M3 responses as the basis for this discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e98f12a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "# helper methods\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89",
   "metadata": {
    "id": "82ea2d32-f0a9-4dc9-bb60-be43399f5b89"
   },
   "outputs": [],
   "source": [
    "# Import the tables of the data set as dataframes.\n",
    "\n",
    "DATA_DIR = './data' # You many change the directory\n",
    "\n",
    "# You can use the nrows=X argument in pd.read_csv to truncate your data\n",
    "users = pd.read_csv('{}/calcularis_small_users.csv'.format(DATA_DIR), index_col=0)\n",
    "events = pd.read_csv('{}/calcularis_small_events.csv'.format(DATA_DIR), index_col=0)\n",
    "subtasks = pd.read_csv('{}/calcularis_small_subtasks.csv'.format(DATA_DIR), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c7eecd",
   "metadata": {},
   "source": [
    "## Task 0: Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec1c9055",
   "metadata": {},
   "source": [
    "**Research question:**\n",
    "* What factors influence the process of learning?  \n",
    "\n",
    "* Which tasks should be solved to obtain the fastest progress? Is there any tasks of this kind? \n",
    "\n",
    "* How in task-based learning we can assume that the student is learnt. Is the time most important? How many correct answers? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e",
   "metadata": {
    "id": "a77f62b0-1945-48f1-8f22-5f6ebda1db8e"
   },
   "source": [
    "## Task 1: Data Preprocessing\n",
    "\n",
    "In this section, you are asked to preprocess your data in a way that is relevant for the model. Please include 1-2 visualizations of features / data explorations that are related to your downstream prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b6078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many events in dataset: 34094\n",
      "How many subtasks in dataset: 55047\n"
     ]
    }
   ],
   "source": [
    "# In subtasks dataset exist more event_id than in events dataset\n",
    "print(f'How many events in dataset: {len(events)}')\n",
    "print(f'How many subtasks in dataset: {len(subtasks)}')\n",
    "subtasks = subtasks[subtasks.event_id < len(events)]\n",
    "\n",
    "# Set the game names in subtasks dataset\n",
    "#subtasks = subtasks.copy()\n",
    "#subtasks['game_name'] = events.iloc[subtasks['event_id']]['game_name'].values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "95f5f236",
   "metadata": {},
   "source": [
    "### Skill graph\n",
    "We decide to base calculation of the lmastery in games on skill graph, which we are downloading below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19b3a688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DOT file and store it as a NetworkX graph\n",
    "dot_file_path = 'data/04_calcularis_skill_map_dot_file.dot'\n",
    "G = read_dot(dot_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph of skills\n",
    "def draw_graph(G):\n",
    "    plt.figure(figsize=(40, 80))\n",
    "    pos = nx.spring_layout(G, k=0.3, iterations=50)\n",
    "    node_sizes = [len(G.adj[node]) * 100 for node in G.nodes]\n",
    "    edge_widths = [1 + len(G.get_edge_data(u, v)) for u, v in G.edges()]\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, alpha=0.5)\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.3, arrowsize=10, arrowstyle='->')\n",
    "    labels = {node: node.replace('\\n', ' ') for node in G.nodes}\n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=10)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('skill_graph')\n",
    "    plt.close()\n",
    "\n",
    "draw_graph(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "98ada42b",
   "metadata": {},
   "source": [
    "![myfig](skill_map.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3cb4097a",
   "metadata": {},
   "source": [
    "### Dataframe with mastery levels\n",
    "At the beginning, we are looking for the games titles in skill map, which fits with game name and skill id found in the dataframe. Then we have to find ancestors of the each game, based on position in the skill map. Thanks to this we can calculate the mastery skill over all games that contributes to development of each skill for all the users.\n",
    "\n",
    "To calculate mastery level we are using methods from utils.py. They are described in comments.\n",
    "\n",
    "Finally we stored created dataframe in dataframe.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82ad7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** processing data for user id == 10 ****\n",
      "**** processing data for user id == 20 ****\n",
      "**** processing data for user id == 30 ****\n",
      "**** processing data for user id == 40 ****\n",
      "**** processing data for user id == 50 ****\n",
      "**** processing data for user id == 60 ****\n",
      "**** processing data for user id == 70 ****\n",
      "**** processing data for user id == 80 ****\n",
      "**** processing data for user id == 90 ****\n",
      "**** processing data for user id == 100 ****\n",
      "**** processing data for user id == 110 ****\n",
      "**** processing data for user id == 120 ****\n",
      "**** processing data for user id == 130 ****\n",
      "**** processing data for user id == 140 ****\n",
      "**** processing data for user id == 150 ****\n",
      "**** processing data for user id == 160 ****\n",
      "**** processing data for user id == 170 ****\n",
      "**** processing data for user id == 180 ****\n",
      "**** processing data for user id == 190 ****\n",
      "**** processing data for user id == 200 ****\n",
      "**** processing data for user id == 210 ****\n",
      "**** processing data for user id == 220 ****\n",
      "**** processing data for user id == 230 ****\n",
      "**** processing data for user id == 240 ****\n",
      "**** processing data for user id == 250 ****\n",
      "**** processing data for user id == 260 ****\n",
      "**** processing data for user id == 270 ****\n",
      "**** processing data for user id == 280 ****\n",
      "**** processing data for user id == 290 ****\n",
      "**** processing data for user id == 300 ****\n",
      "**** processing data for user id == 310 ****\n",
      "**** processing data for user id == 320 ****\n",
      "**** processing data for user id == 330 ****\n",
      "**** processing data for user id == 340 ****\n",
      "**** processing data for user id == 350 ****\n",
      "**** processing data for user id == 360 ****\n",
      "**** processing data for user id == 370 ****\n",
      "**** processing data for user id == 380 ****\n",
      "**** processing data for user id == 390 ****\n",
      "**** processing data for user id == 400 ****\n",
      "**** processing data for user id == 410 ****\n",
      "**** processing data for user id == 420 ****\n",
      "**** processing data for user id == 430 ****\n",
      "**** processing data for user id == 440 ****\n",
      "**** processing data for user id == 450 ****\n",
      "**** processing data for user id == 460 ****\n",
      "**** processing data for user id == 470 ****\n",
      "**** processing data for user id == 480 ****\n",
      "**** processing data for user id == 490 ****\n",
      "**** processing data for user id == 500 ****\n",
      "**** processing data for user id == 510 ****\n",
      "**** processing data for user id == 520 ****\n",
      "**** processing data for user id == 530 ****\n",
      "**** processing data for user id == 540 ****\n",
      "**** processing data for user id == 550 ****\n",
      "**** processing data for user id == 560 ****\n",
      "**** processing data for user id == 570 ****\n",
      "**** processing data for user id == 580 ****\n",
      "**** processing data for user id == 590 ****\n",
      "**** processing data for user id == 600 ****\n",
      "**** processing data for user id == 610 ****\n",
      "**** processing data for user id == 620 ****\n",
      "**** processing data for user id == 630 ****\n",
      "**** processing data for user id == 640 ****\n",
      "**** processing data for user id == 650 ****\n",
      "**** processing data for user id == 660 ****\n",
      "**** processing data for user id == 670 ****\n",
      "**** processing data for user id == 680 ****\n",
      "**** processing data for user id == 690 ****\n",
      "**** processing data for user id == 700 ****\n",
      "**** processing data for user id == 710 ****\n",
      "**** processing data for user id == 720 ****\n",
      "**** processing data for user id == 730 ****\n",
      "**** processing data for user id == 740 ****\n",
      "**** processing data for user id == 750 ****\n",
      "**** processing data for user id == 760 ****\n",
      "**** processing data for user id == 770 ****\n",
      "**** processing data for user id == 780 ****\n",
      "**** processing data for user id == 790 ****\n",
      "**** processing data for user id == 800 ****\n",
      "**** processing data for user id == 810 ****\n",
      "**** processing data for user id == 820 ****\n",
      "**** processing data for user id == 830 ****\n",
      "**** processing data for user id == 840 ****\n",
      "**** processing data for user id == 850 ****\n",
      "**** processing data for user id == 860 ****\n",
      "**** processing data for user id == 870 ****\n",
      "**** processing data for user id == 880 ****\n",
      "**** processing data for user id == 890 ****\n",
      "**** processing data for user id == 900 ****\n",
      "**** processing data for user id == 910 ****\n",
      "**** processing data for user id == 920 ****\n",
      "**** processing data for user id == 930 ****\n",
      "**** processing data for user id == 940 ****\n",
      "**** processing data for user id == 950 ****\n",
      "**** processing data for user id == 960 ****\n",
      "**** processing data for user id == 970 ****\n",
      "**** processing data for user id == 980 ****\n",
      "**** processing data for user id == 990 ****\n",
      "**** processing data for user id == 1000 ****\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe with multindex [user_id, week, game]\n",
    "def create_dataframe_multi_index(G, how_many=100, verbose=False):\n",
    "\n",
    "    # Create empty dataframe\n",
    "    multi_index = [[], [], []]\n",
    "    df = pd.DataFrame(columns = ['mastery_level', 'mastery_level_diff'], index = multi_index)\n",
    "    df.index = df.index.set_names(['user_id', 'game_name', 'week'])\n",
    "\n",
    "    subtasks_events = subtasks.merge(events, on='event_id')\n",
    "\n",
    "    for user_id, user in users.iterrows(): \n",
    "        # Find user_subtasks \n",
    "        user_subtasks = find_user_subtasks(subtasks_events, user_id)[['week_number', 'game_name', 'skill_id', 'correct']]\n",
    "        \n",
    "        # Create index for the user:\n",
    "        # Get unique games names\n",
    "        game_names = events.loc[subtasks['event_id']]['game_name'].unique()\n",
    "\n",
    "        # Get unique weeks\n",
    "        unique_weeks = user_subtasks['week_number'].unique()\n",
    "\n",
    "        len_weeks = len(unique_weeks)\n",
    "        len_game_names = len(game_names)\n",
    "\n",
    "        user_ids = [user_id for i in range(len_weeks * len_game_names)]\n",
    "\n",
    "        user_unique_weeks = user_subtasks['week_number'].unique()\n",
    "        user_unique_weeks = np.concatenate([user_unique_weeks]* (len_game_names))\n",
    "\n",
    "        user_unique_games = [game for game in game_names for week in range(len_weeks)]\n",
    "\n",
    "        tuples = list(zip(user_ids, user_unique_games, user_unique_weeks))\n",
    "\n",
    "        # Assign index values\n",
    "        index = pd.MultiIndex.from_tuples(tuples, names=['user_id', 'game_name', 'week'])\n",
    "        user_df = pd.DataFrame(columns = ['mastery_level', 'mastery_level_diff'], index = index)\n",
    "\n",
    "        # Calculate mastery level\n",
    "        mastery_level = []\n",
    "        for game in game_names:\n",
    "            for week in unique_weeks:\n",
    "                # Find info about statistics of the user for the game for the week\n",
    "                associated_events = user_subtasks[(user_subtasks['game_name'] == game) & (user_subtasks['week_number'] == week)]\n",
    "                \n",
    "                # If the user played the game during the week\n",
    "                if not associated_events.empty:\n",
    "                    mean_skill = associated_events['skill_id'].mean()\n",
    "                    lv = calculate_mastery_level(G, user_subtasks, week, game, mean_skill)\n",
    "                    mastery_level.append(lv)\n",
    "                # If the user did not play the game during the week, but we can get previous statictics\n",
    "                elif week > unique_weeks[0]:\n",
    "                    mastery_level.append(mastery_level[-1])\n",
    "                # If the week == 1 and player did not play the game\n",
    "                else: \n",
    "                    mastery_level.append(0.0)\n",
    "                \n",
    "\n",
    "        # Assign mastery levls\n",
    "        mastery_level = pd.DataFrame(mastery_level, columns = ['mastery_level'])\n",
    "        mastery_level.index = index\n",
    "        user_df['mastery_level'] = mastery_level\n",
    "\n",
    "        # Assign the difference of mastery lvls\n",
    "        user_df['mastery_level_diff'] = user_df['mastery_level'].diff()\n",
    "        user_df.loc[user_df.index.get_level_values('week') == 1, 'mastery_level_diff'] = 0.0\n",
    "\n",
    "        # Add stats of the user to the dataframe\n",
    "        df = pd.concat([df, user_df], axis=0)\n",
    "\n",
    "        # Display info\n",
    "        if user_id % 10 == 0 and verbose:\n",
    "            print(f'**** processing data for user id == {user_id} ****')\n",
    "        # Calculate for fraction of all users\n",
    "        if user_id > how_many:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "df = create_dataframe_multi_index(G, len(users), True)\n",
    "convert_to_csv(df, 'dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29b82ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_from_csv('dataframe.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6734d89e",
   "metadata": {},
   "source": [
    "### Display results\n",
    "We are creating two graphs, each of them showing one column in our dataframe for 10 users for chosen game. \n",
    "- mastery_level: it is representation of development of skill over time\n",
    "- mastery_level: it represents the progress between each week ver time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f11b9b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ewa.miazga\\OneDrive - Politechnika Warszawska\\Pulpit\\studies\\SEM 4\\MLFBD\\milestone-4-calcularis-crusaders\\project\\milestone-04\\utils.py:102: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  if df.loc[(user, game), col].sum() != 0.0:\n",
      "c:\\Users\\ewa.miazga\\OneDrive - Politechnika Warszawska\\Pulpit\\studies\\SEM 4\\MLFBD\\milestone-4-calcularis-crusaders\\project\\milestone-04\\utils.py:102: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  if df.loc[(user, game), col].sum() != 0.0:\n"
     ]
    }
   ],
   "source": [
    "# Display mastery levels\n",
    "def show_mastery_details(df, users, game, col):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    for i, user in enumerate(users):\n",
    "        temp_df = df.sort_index().loc[(user, game), :]\n",
    "        ax.plot(temp_df.index, temp_df[col], label=f'{user}')\n",
    "\n",
    "    ax.set_title(f'{col} of {game} Over Time')\n",
    "    ax.set_xlabel('Weeks')\n",
    "    ax.set_ylabel(col)\n",
    "    ax.legend(title='User ID', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.savefig(f'{col}.png')\n",
    "    plt.close()\n",
    "\n",
    "random_user_ids = get_random_ids(df, 10, 'Subitizing', 'mastery_level')\n",
    "show_mastery_details(df, random_user_ids, 'Subitizing', 'mastery_level')\n",
    "\n",
    "random_user_ids = get_random_ids(df, 10, 'Subitizing', 'mastery_level_diff')\n",
    "show_mastery_details(df, random_user_ids, 'Subitizing', 'mastery_level_diff')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf2a05cb",
   "metadata": {},
   "source": [
    "*Your discussion about your processing decisions goes here*\n",
    "\n",
    "#### mastery level\n",
    "We can track the progress or regress of developing of skill, what is important not many users achive the mastery level above 0.5 at the end of their learning, so it may mean that they drop the learning process because of some reasons, which could be boredom or lack of motivation to continue.\n",
    "\n",
    "![mastery_level](mastery_level.png)\n",
    "\n",
    "#### mastery level differences\n",
    "What is of much significance, most of users are not making progress during the period of research. They only play the game in some of the weeks, where in others they are not progressing at all. This could provide us some insights why they are not making great progess which can be observed in first plot. Also the differences between mastery levels over weeks are not bigger than 0.4. The ratio between how much of them making progress and regress is close to 0.5\n",
    "\n",
    "![mastery_level_diff](mastery_level_diff.png)\n",
    "\n",
    "We can conclude that the values of this column and patterns that can be found in this graphs are completely different. These will be used to check which allows us to produce better predictions, as the first one might be misinterpreted by our model, because eventhough player is not playing the game his mastery skill is maintained.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85633adb-d317-4ee3-bf06-e9f82f589c41",
   "metadata": {
    "id": "85633adb-d317-4ee3-bf06-e9f82f589c41"
   },
   "source": [
    "## Task 2: Model Building\n",
    "\n",
    "Train a model for your research question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b65ebd-c148-4ae8-833e-018411eeda86",
   "metadata": {
    "id": "90b65ebd-c148-4ae8-833e-018411eeda86"
   },
   "outputs": [],
   "source": [
    "# Your code for training a model goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dd126",
   "metadata": {},
   "source": [
    "*Your discussion about your model training goes here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af",
   "metadata": {
    "id": "b3c9a655-cec9-4c57-aec7-7a982f57a3af"
   },
   "source": [
    "## Task 3: Model Evaluation\n",
    "In this task, you will use metrics to evaluate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for model evaluation goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57e3f3d",
   "metadata": {},
   "source": [
    "*Your discussion/interpretation about your model's behavior goes here*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1607d4b3",
   "metadata": {},
   "source": [
    "## Task 4: Team Reflection\n",
    "Please describe the contributions of each team member to Milestone 4. Reflect on how you worked as team: what went well, what can be improved for the next milestone?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb3dd783",
   "metadata": {},
   "source": [
    "*Your discussion about team responsibilities goes here*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2-classtime-sciper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a552de0a42a98a523e8f67ee9117f7b13e645144e58150911097f2b178b1554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
